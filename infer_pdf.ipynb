{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'O',\n",
    "    'B-QUESTION',\n",
    "    'B-ANSWER',\n",
    "    'B-HEADER',\n",
    "    'I-ANSWER',\n",
    "    'I-QUESTION',\n",
    "    'I-HEADER'\n",
    "]\n",
    "id2label = {v: k for v, k in enumerate(labels)}\n",
    "label2id = {k: v for v, k in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `\"tokenizer_class\": \"XLMRobertaTokenizer\"` in config.json with `\"tokenizer_class\": \"LayoutXLMTokenizer\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutXLMProcessor, LayoutLMv2ForTokenClassification\n",
    "\n",
    "processor = LayoutXLMProcessor.from_pretrained('./test-ner')\n",
    "model = LayoutLMv2ForTokenClassification.from_pretrained(\"./test-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_box(bbox, width, height):\n",
    "    return [\n",
    "         width * (bbox[0] / 1000),\n",
    "         height * (bbox[1] / 1000),\n",
    "         width * (bbox[2] / 1000),\n",
    "         height * (bbox[3] / 1000),\n",
    "    ]\n",
    "\n",
    "def iob_to_label(label):\n",
    "    label = label[2:]\n",
    "    if not label:\n",
    "        return 'other'\n",
    "    return label\n",
    "\n",
    "label2color = {'question':'blue', 'answer':'green', 'header':'orange', 'other':'violet'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee133b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(image, processor, model, label2color):\n",
    "    image = image.convert(\"RGB\")\n",
    "    encoding = processor(image, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True, max_length=514)\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    token_boxes = encoding.bbox.squeeze().tolist()\n",
    "\n",
    "    width, height = image.size\n",
    "    is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
    "\n",
    "    true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
    "    true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for prediction, box in zip(true_predictions, true_boxes):\n",
    "        predicted_label = iob_to_label(prediction).lower()\n",
    "        draw.rectangle(box, outline=label2color[predicted_label])\n",
    "        draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9185bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [convert_from_path(img_path) for img_path in Path('./infer/pdf/').glob('*.pdf')]\n",
    "imgs = list(chain.from_iterable(imgs))\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [infer(image, processor, model, label2color) for image in tqdm(imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42426b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in outputs:\n",
    "    display(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f0822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13cabaac22e3a84ec22f05bd8d8ac8de848714bc361e863c45acbcd1b2b4dff7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
