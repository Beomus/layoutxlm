{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516960e6-b275-4ace-89fb-baf9c3cedf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682681a5-b9ea-4ab2-9474-7575666ff39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "datasets = load_dataset(\"nielsr/XFUN\", \"xfun.ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94508bb-3eb5-4126-af77-82bbdda2b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = datasets['train'].features['labels'].feature.names\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05d5cd-4c2f-4cbb-9427-60fa2b37c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {v: k for v, k in enumerate(labels)}\n",
    "label2id = {k: v for v, k in enumerate(labels)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7d14b-0739-415d-b6a4-8279106d581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutXLMTokenizer, LayoutXLMProcessor, LayoutLMv2FeatureExtractor\n",
    "\n",
    "processor = LayoutXLMProcessor.from_pretrained('./test-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24db94-6de2-46a1-a0b3-4158cca51269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "image = Image.open('./infer/ja.val/ja_val_0.jpg').convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10811d4-4781-404d-87da-b195f3931e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = processor(image, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "offset_mapping = encoding.pop('offset_mapping')\n",
    "print(encoding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b01f30-0b6a-49ed-b7b4-6ce02bb0bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66811ab7-cb11-44c9-93e5-38bed5f886d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv2ForTokenClassification\n",
    "\n",
    "# load the fine-tuned model from the hub\n",
    "model = LayoutLMv2ForTokenClassification.from_pretrained(\"./test-ner\")\n",
    "\n",
    "# forward pass\n",
    "outputs = model(**encoding)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fa7b1-7eeb-4354-8479-b2351492faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_box(bbox, width, height):\n",
    "     return [\n",
    "         width * (bbox[0] / 1000),\n",
    "         height * (bbox[1] / 1000),\n",
    "         width * (bbox[2] / 1000),\n",
    "         height * (bbox[3] / 1000),\n",
    "     ]\n",
    "\n",
    "predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "token_boxes = encoding.bbox.squeeze().tolist()\n",
    "\n",
    "width, height = image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d21030-e80a-4cb4-b975-8185ebe56ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
    "\n",
    "true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
    "true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda07169-5d84-4081-87cd-cdad5a89b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_predictions)\n",
    "print(true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828b986-519c-4845-b255-148b40e9cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "def iob_to_label(label):\n",
    "    label = label[2:]\n",
    "    if not label:\n",
    "      return 'other'\n",
    "    return label\n",
    "\n",
    "label2color = {'question':'blue', 'answer':'green', 'header':'orange', 'other':'violet'}\n",
    "\n",
    "for prediction, box in zip(true_predictions, true_boxes):\n",
    "    predicted_label = iob_to_label(prediction).lower()\n",
    "    draw.rectangle(box, outline=label2color[predicted_label])\n",
    "    draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23b998-7391-4d8e-9508-621e9b2f8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(img_path, processor, model, label2color):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    encoding = processor(image, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True, max_length=514)\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    token_boxes = encoding.bbox.squeeze().tolist()\n",
    "\n",
    "    width, height = image.size\n",
    "    is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
    "\n",
    "    true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
    "    true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for prediction, box in zip(true_predictions, true_boxes):\n",
    "        predicted_label = iob_to_label(prediction).lower()\n",
    "        draw.rectangle(box, outline=label2color[predicted_label])\n",
    "        draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d744c-65d6-4fe6-9f5b-359b7e0f72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a747d94-7166-4413-8223-e7cfcf5b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "imgs = [img_path for img_path in Path('./infer/ja.val/').glob('*.jpg')][:50]\n",
    "outputs = [infer(img_path, processor, model) for img_path in tqdm(imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3127234-e766-413d-a358-a0a41a639265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in outputs:\n",
    "    display(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc9e66-e360-414d-ab60-2c75fe46d634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
